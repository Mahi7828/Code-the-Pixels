{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OpenCV Basics with Python**\n",
    "<font size=\"3\">\n",
    " This script is designed to introduce the fundamental operations in the OpenCV library, often used in electronics and robotics applications. The following operations are demonstrated using two primary libraries:\n",
    "\n",
    "<br>\n",
    " <ul>\n",
    "    <li>NumPy\n",
    "    <li>cv2\n",
    "    </ul>\n",
    "\n",
    "This document is offered by **Electronics & Robotics Club**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully!\n",
      "Image size: (1280, 949, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(r\"joker_1.jpg\")\n",
    "\n",
    "# Check if the image was successfully loaded\n",
    "if image is None:\n",
    "    print(\"Error loading image\")\n",
    "else:\n",
    "    print(\"Image loaded successfully!\")\n",
    "    print(\"Image size:\", image.shape)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Loaded Image\", image)\n",
    "    cv2.waitKey(0)  # Wait for a key press\n",
    "    cv2.destroyAllWindows()  # Close the display window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "id": "qVDJeKulXgG1",
    "outputId": "7e5fa49a-c403-465f-dd71-fb8269fe5ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded image is of type: <class 'numpy.ndarray'>\n",
      "The loaded image is of size: (720, 720, 3)\n",
      "intensity at index [47 47 31]\n",
      "size is (720, 720, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "#checking type of image\n",
    "print(\"The loaded image is of type:\",type(image))\n",
    "print(\"The loaded image is of size:\",image.shape)\n",
    "print(\"intensity at index\", image[719][719])\n",
    "image.size\n",
    "#Resizing the image because it is huge!\n",
    "image = cv2.resize(image, (720, 720))\n",
    "print(\"size is\",image.shape)\n",
    "# checking some values?\n",
    "print(type(image[710][132]))\n",
    "#error index out of range will get generated if you resize the image size to 720 to 720, as now only 720 pixels are there\n",
    "#so the numpy array doesn't have indices beyond 720\n",
    "#uint8 - 8 bit unsigned integer, so 0 to 255\n",
    "#double(image)/255 -> 0-1 -> ^gamma -> uint8()\n",
    "#Displaying the image\n",
    "#in other ides you can use cv2.imshow(\"window name\", imae) -> for google colab you have to use cv2_imshow(image)\n",
    "cv2.imshow('Window Name', image)\n",
    "#Wait till key is pressed\n",
    "k=cv2.waitKey(1000)\n",
    "#Close all the windows\n",
    "cv2.destroyAllWindows()\n",
    "print(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JirGxRKwht7v",
    "outputId": "6c679eff-82fc-4461-80d8-14780ac2014d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image:\n",
      "Flipped Vertically:\n",
      "Flipped Horizontally:\n",
      "Flipped Both Vertically and Horizontally:\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Flip the image vertically (arg is 0)\n",
    "flipped_vertically = cv2.flip(image, 0)\n",
    "\n",
    "# Flip the image horizontally (arg is 1)\n",
    "flipped_horizontally = cv2.flip(image, 1)\n",
    "\n",
    "# Flip the image both vertically and horizontally (arg is -1)\n",
    "flipped_both = cv2.flip(image, -1)\n",
    "\n",
    "# Display the original and flipped images\n",
    "print(\"Original Image:\")\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "\n",
    "print(\"Flipped Vertically:\")\n",
    "cv2.imshow(\"Flipped Vertically\", flipped_vertically)\n",
    "\n",
    "print(\"Flipped Horizontally:\")\n",
    "cv2.imshow(\"Flipped Horizontally\", flipped_horizontally)\n",
    "\n",
    "print(\"Flipped Both Vertically and Horizontally:\")\n",
    "cv2.imshow(\"Flipped Both\", flipped_both)\n",
    "\n",
    "# Wait for a key press and then close all windows\n",
    "cv2.waitKey(0)  # Wait indefinitely until a key is pressed\n",
    "cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jeNx1Zr3ZPDA",
    "outputId": "f4d6037f-72b4-40de-cd3b-055a62c213e6"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'image_np' is your numpy array containing the image buffer\n",
    "# In this example, you could load an image as a buffer\n",
    "with open('C:/Users/mahim/Downloads/joker_1.jpg', 'rb') as f:\n",
    "    image_np = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "\n",
    "# Decode the image\n",
    "image = cv2.imdecode(image_np, -1)\n",
    "\n",
    "# Resizing the image to 500x500 pixels\n",
    "image = cv2.resize(image, (500, 500))\n",
    "\n",
    "# Separating each color channel (OpenCV uses BGR format)\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "# Displaying the original and separated color channels\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Blue Channel\", B)\n",
    "cv2.imshow(\"Green Channel\", G)\n",
    "cv2.imshow(\"Red Channel\", R)\n",
    "\n",
    "# Wait indefinitely for a key press\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QjOGpNVLZlPb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Converting image to HSV\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Converting image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Stack the original and HSV images horizontally for display\n",
    "stacked_images = np.hstack([image, hsv])\n",
    "\n",
    "# Display the images with window names\n",
    "cv2.imshow(\"Original and HSV Image\", stacked_images)\n",
    "cv2.imshow(\"Grayscale Image\", gray)\n",
    "\n",
    "# Wait till a key is pressed\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "P_UVE7zKZpG1",
    "outputId": "579b05df-da40-4b66-91be-8f6149cbef22"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Resizing the grayscale image to 500x500\n",
    "gray = cv2.resize(gray, (500, 500))\n",
    "\n",
    "# Applying different types of thresholding\n",
    "ret, thresh1 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(gray, 127, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(gray, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(gray, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "# Stacking the images horizontally\n",
    "stacked_1 = np.hstack([gray, thresh1])\n",
    "stacked_2 = np.hstack([thresh2, thresh3])\n",
    "stacked_3 = np.hstack([thresh4, thresh5])\n",
    "\n",
    "# Displaying the stacked threshold images with proper window names\n",
    "cv2.imshow(\"Gray and THRESH_BINARY\", stacked_1)\n",
    "cv2.imshow(\"THRESH_BINARY_INV and THRESH_TRUNC\", stacked_2)\n",
    "cv2.imshow(\"THRESH_TOZERO and THRESH_TOZERO_INV\", stacked_3)\n",
    "\n",
    "# Wait till a key is pressed\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "deYZ7hK4ZrSf",
    "outputId": "e5937e2f-0b63-4fda-c169-09e839663db9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Applying adaptive thresholding\n",
    "adaptive_thresh1 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "adaptive_thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Stacking the adaptive threshold images horizontally\n",
    "stacked_adaptive = np.hstack([adaptive_thresh1, adaptive_thresh2])\n",
    "\n",
    "# Displaying the stacked adaptive threshold images with a proper window name\n",
    "cv2.imshow(\"Adaptive Thresholding - Mean and Gaussian\", stacked_adaptive)\n",
    "\n",
    "# Wait till a key is pressed\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Tv_f1lmZZuFQ",
    "outputId": "f85d402f-2ac9-44c4-a782-157b4deb0348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSV value of green: [[[ 60 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Getting the color values in HSV\n",
    "col = np.uint8([[[0, 255, 0]]])  # uint8 array for color green in BGR\n",
    "hsv_col = cv2.cvtColor(col, cv2.COLOR_BGR2HSV)  # Converting to HSV\n",
    "print(\"HSV value of green:\", hsv_col)  # Print the HSV value of green for reference\n",
    "\n",
    "# Defining the lower and upper range for the green color in HSV\n",
    "lower = np.array([50, 50, 50])  # Lower bound\n",
    "upper = np.array([70, 255, 255])  # Upper bound\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "# Assuming 'image' is already loaded and defined\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # Convert image to HSV\n",
    "\n",
    "# Using the inRange function to create a binary mask\n",
    "mask = cv2.inRange(hsv, lower, upper)  # Creating the mask\n",
    "\n",
    "# Applying the mask on the original image\n",
    "extracted = cv2.bitwise_and(image, image, mask=mask)  # Extracting the color\n",
    "\n",
    "# Displaying the original image, mask, and extracted result with proper window names\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Binary Mask\", mask)\n",
    "cv2.imshow(\"Extracted Color\", extracted)\n",
    "\n",
    "# Wait till a key is pressed\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1IzlY_zxkCZJ",
    "outputId": "83ef9c8f-c7d4-46c4-ca0f-d02021621d03"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to the grayscale image to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Perform Canny edge detection\n",
    "# The two threshold values (100 and 200) can be adjusted to detect more or fewer edges\n",
    "edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "# Display the original image, grayscale image, and edges with proper window names\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Grayscale Image\", gray)\n",
    "cv2.imshow(\"Edges Detected (Canny)\", edges)\n",
    "\n",
    "# Wait for a key press and close all windows\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K5bhSwfoZxah",
    "outputId": "90dff8bc-5ff7-499f-8691-cdad8276e0ac"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Size for the filter\n",
    "kernel = 5\n",
    "\n",
    "# Applying different types of blurring\n",
    "# Box filter\n",
    "blurred_img_B = cv2.blur(image, (kernel, kernel))\n",
    "# Gaussian filter\n",
    "blurred_img_G = cv2.GaussianBlur(image, (kernel, kernel), 0)\n",
    "# Median filter\n",
    "blurred_img_M = cv2.medianBlur(image, kernel)\n",
    "\n",
    "# Resize all images to 500x500 pixels\n",
    "image = cv2.resize(image, (500, 500))\n",
    "blurred_img_B = cv2.resize(blurred_img_B, (500, 500))\n",
    "blurred_img_G = cv2.resize(blurred_img_G, (500, 500))\n",
    "blurred_img_M = cv2.resize(blurred_img_M, (500, 500))\n",
    "\n",
    "# Displaying the original and blurred images with proper window names\n",
    "cv2.imshow(\"Original Image vs Box Filter\", np.hstack([image, blurred_img_B]))\n",
    "cv2.imshow(\"Gaussian Filter vs Median Filter\", np.hstack([blurred_img_G, blurred_img_M]))\n",
    "\n",
    "# Wait till a key is pressed\n",
    "k = cv2.waitKey(0)\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKWElk-sZzIj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
